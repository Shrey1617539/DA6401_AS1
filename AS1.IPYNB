{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function_cal(a, activation_function):\n",
    "    if activation_function == 'sigmoid':\n",
    "        return (1/(1+np.exp(-1*a)))\n",
    "    \n",
    "    if activation_function == 'tanh':\n",
    "        return (np.exp(a)-np.exp(-1*a))/(np.exp(a)+np.exp(-1*a))\n",
    "    \n",
    "    if activation_function == 'ReLU':\n",
    "        return a*(a>0)\n",
    "    \n",
    "    if activation_function == 'linear':\n",
    "        return a\n",
    "    \n",
    "    if activation_function == 'softmax':\n",
    "        a = np.exp(a)\n",
    "        a /= np.sum(a)\n",
    "        return a\n",
    "\n",
    "def gradient_activation_function(a, activation_function):\n",
    "    if activation_function == 'sigmoid':\n",
    "        z = (1/(1+np.exp(-1*a)))\n",
    "        return z*(1-z)\n",
    "    \n",
    "    if activation_function == 'tanh':\n",
    "        z = (np.exp(a)-np.exp(-1*a))/(np.exp(a)+np.exp(-1*a))\n",
    "        return (1 - (z**2))\n",
    "    \n",
    "    if activation_function == 'ReLU':\n",
    "        return 1*(a>0)\n",
    "\n",
    "\n",
    "def feedforward(x, weights, bias, activation_function):\n",
    "    a = []\n",
    "    h = []\n",
    "    x = x.flatten()\n",
    "    x = x.reshape(-1,1)\n",
    "\n",
    "    for layer in range(len(weights)-1):\n",
    "        x = bias[layer] + np.dot(weights[layer], x)\n",
    "        a.append(x)\n",
    "        x = activation_function_cal(x, activation_function[layer])\n",
    "        h.append(x)\n",
    "\n",
    "    x = bias[-1] + np.dot(weights[-1], x)\n",
    "    a.append(x)\n",
    "    x = activation_function_cal(x, activation_function[-1])\n",
    "    h.append(x)\n",
    "\n",
    "    return x, a, h\n",
    "    \n",
    "def loss_calculations(y_pred, y):\n",
    "    print(y_pred[np.arange(y_pred.shape[0]), y])\n",
    "    loss = -1*np.log(y_pred[np.arange(y_pred.shape[0]), y])\n",
    "    loss = np.average(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def backpropagation(X, Y, weights, bias, activation_function):\n",
    "    d_W = []\n",
    "    d_b = []\n",
    "\n",
    "    y_pred, a, h = feedforward(X, weights = weights, bias= bias, activation_function= activation_function)\n",
    "    e_y = np.zeros(y_pred.shape)\n",
    "    e_y[Y] = 1\n",
    "    grad_al = (y_pred - e_y).reshape(-1,1)\n",
    "    grad_hl = 0\n",
    "\n",
    "    for layer in reversed(range(1, len(weights))):\n",
    "        d_W.append(np.dot(grad_al, h[layer -1].T))\n",
    "        d_b.append(grad_al)\n",
    "\n",
    "        grad_hl = np.dot(weights[layer].T, grad_al)\n",
    "        grad_al = grad_hl * gradient_activation_function(a[layer - 1], activation_function[layer - 1])\n",
    "    \n",
    "    d_W.append(np.dot(grad_al, X.flatten().reshape(-1,1).T))\n",
    "    d_b.append(grad_al)\n",
    "\n",
    "    d_W = list(reversed(d_W))\n",
    "    d_b = list(reversed(d_b))\n",
    "    \n",
    "    return d_W, d_b\n",
    "    \n",
    "def reset_d_weights(weights, bias):\n",
    "    d_W = []\n",
    "    d_b = []\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        d_W.append(np.zeros(weights[i].shape))\n",
    "        d_b.append(np.zeros(bias[i].shape))\n",
    "    \n",
    "    return d_W, d_b\n",
    "\n",
    "\n",
    "def gradient_descent(X_data, Y_data, weights, bias, epochs, activation_function, learning_rate = 0.01, beta = 0, batch_size = None, optimization_method = None):\n",
    "    if batch_size == None:\n",
    "        batch_size = X_data.shape[0]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        d_W, d_b = reset_d_weights(weights, bias)\n",
    "        u_W, u_b = reset_d_weights(weights, bias)\n",
    "        \n",
    "        for i in range(X_data.shape[0]):\n",
    "            X = X_data[i]\n",
    "            Y = Y_data[i]\n",
    "\n",
    "            if optimization_method == 'nesterov':\n",
    "                for j in range(len(weights)):\n",
    "                    weights[j] -= beta*u_W[j]\n",
    "                    bias[j] -= beta*u_b[j]\n",
    "\n",
    "            d_W_part, d_b_part = backpropagation(X, Y, weights = weights, bias = bias, activation_function = activation_function)\n",
    "\n",
    "            for j in range(len(weights)):\n",
    "                d_W[j] += d_W_part[j]\n",
    "                d_b[j] += d_b_part[j]\n",
    "\n",
    "            if optimization_method == None or optimization_method == 'gd':\n",
    "\n",
    "                if (i+1)%batch_size == 0:\n",
    "                    d_W = [x/batch_size for x in d_W]  \n",
    "                    d_b = [x/batch_size for x in d_b]\n",
    "\n",
    "                    for j in range(len(weights)):\n",
    "                        weights[j] -= learning_rate * d_W[j]\n",
    "                        bias[j] -= learning_rate * d_b[j]\n",
    "\n",
    "                    d_W, d_b = reset_d_weights(weights, bias)\n",
    "\n",
    "            if optimization_method == 'sgd':\n",
    "\n",
    "                for j in range(len(weights)):\n",
    "                    weights[j] -= learning_rate * d_W[j]\n",
    "                    bias[j] -= learning_rate * d_b[j]\n",
    "\n",
    "                d_W, d_b = reset_d_weights(weights, bias)\n",
    "            \n",
    "            if optimization_method == 'momentum':\n",
    "\n",
    "                if (i+1)%batch_size == 0:\n",
    "                    d_W = [x/batch_size for x in d_W]\n",
    "                    d_b = [x/batch_size for x in d_b]\n",
    "\n",
    "                    for j in range(len(weights)):\n",
    "                        u_W[j] = beta*u_W[j] + learning_rate*d_W[j]\n",
    "                        u_b[j] = beta*u_b[j] + learning_rate*d_b[j]\n",
    "\n",
    "                        weights[j] -= u_W[j]\n",
    "                        bias[j] -= u_b[j]\n",
    "                    d_W, d_b = reset_d_weights(weights, bias)\n",
    "\n",
    "            if optimization_method == 'nesterov':\n",
    "                \n",
    "                for j in range(len(weights)):\n",
    "                    weights[j] += beta*u_W[j]\n",
    "                    bias[j] += beta*u_b[j]\n",
    "\n",
    "                if (i+1)%batch_size == 0:\n",
    "                    d_W = [x/batch_size for x in d_W]\n",
    "                    d_b = [x/batch_size for x in d_b]\n",
    "\n",
    "                    for j in range(len(weights)):\n",
    "                        u_W[j] = beta*u_W[j] + learning_rate*d_W[j]\n",
    "                        u_b[j] = beta*u_b[j] + learning_rate*d_b[j]\n",
    "\n",
    "                        weights[j] -= u_W[j]\n",
    "                        bias[j] -= u_b[j]\n",
    "                    d_W, d_b = reset_d_weights(weights, bias)\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.44917362, -0.42785264, -0.91416361, ...,  0.63551535,\n",
       "           0.36167296, -0.40050742],\n",
       "         [ 0.15136422,  0.13402014,  0.14228283, ..., -2.06891251,\n",
       "          -0.0565025 ,  0.4216988 ],\n",
       "         [-2.30904227,  0.95621097,  0.23588649, ...,  1.97695164,\n",
       "          -0.91434222,  0.03412569],\n",
       "         ...,\n",
       "         [ 1.28954919, -0.14680537, -0.8656748 , ..., -1.21858533,\n",
       "           0.54745473, -0.09161309],\n",
       "         [-0.14819281, -0.13570201, -0.33439728, ...,  0.9086913 ,\n",
       "          -0.06687325,  1.67495815],\n",
       "         [-0.08199637,  0.7342912 ,  0.08143145, ...,  0.16718051,\n",
       "           0.75360995, -0.49686883]]),\n",
       "  array([[-9.22677614e-01, -3.26747251e-02, -1.84706516e+00,\n",
       "          -2.72292543e-01, -1.78849852e+00, -2.06191590e+00,\n",
       "           1.00485771e+00, -9.48005183e-01,  1.01658822e+00,\n",
       "           1.06927403e+00, -5.35525418e-01, -1.48594494e+00,\n",
       "          -8.96918188e-01,  1.93621924e+00,  9.22726284e-02,\n",
       "          -9.22596407e-01, -1.69413471e+00, -1.22498380e+00,\n",
       "          -1.36166261e+00,  6.72348662e-01,  1.02602568e+00,\n",
       "          -6.38925798e-01,  7.21978022e-01, -2.56879844e+00,\n",
       "           5.74334707e-01,  9.81915135e-01,  4.14151378e-01,\n",
       "          -1.03081886e+00, -1.67025310e+00,  8.21235197e-01,\n",
       "          -8.05298053e-01,  5.61219844e-01],\n",
       "         [ 7.85719381e-01,  4.78891263e-01,  1.68183755e-01,\n",
       "           7.26276841e-01, -1.12065291e+00, -1.67748881e+00,\n",
       "          -5.59856680e-01, -5.28195655e-01, -1.16405885e+00,\n",
       "           2.28050331e-02, -6.10764984e-01,  2.62034778e-01,\n",
       "          -6.69571948e-01,  1.74245596e+00, -3.09209785e-01,\n",
       "           2.16840102e-01, -1.52235200e-01,  8.10565083e-01,\n",
       "          -6.45932916e-01, -9.14524584e-01,  3.56871296e-01,\n",
       "           9.58677586e-01, -4.34673244e+00,  3.18386183e+00,\n",
       "           7.47388623e-01,  1.06923030e+00, -1.82922014e+00,\n",
       "          -2.35843433e-01, -1.46838869e+00, -5.88423161e-01,\n",
       "           1.77351713e-01, -9.63709314e-01],\n",
       "         [-1.52095891e+00,  1.33635800e+00, -5.31322569e-02,\n",
       "          -4.01705035e-01, -3.03508318e+00,  1.66117989e+00,\n",
       "          -5.17300384e-01, -1.59543654e-01, -1.76278402e+00,\n",
       "           1.73195976e+00, -1.64636543e+00,  6.10066497e-01,\n",
       "          -6.49493829e-01, -5.76048917e-01, -6.63506389e-02,\n",
       "           9.67209268e-01, -1.24471576e-01,  4.28899341e-01,\n",
       "          -1.35146316e+00, -3.20018472e-01,  3.77216044e-01,\n",
       "           2.10798082e-01, -8.77491950e-01, -1.19274828e-01,\n",
       "          -7.21624930e-02, -5.18968483e-01,  1.37081687e+00,\n",
       "          -1.04670344e+00,  1.84820234e+00, -1.00241641e+00,\n",
       "           6.24699653e-01, -1.00407950e+00],\n",
       "         [ 1.00492279e+00,  1.60066614e+00,  7.88327697e-01,\n",
       "          -4.81320075e-01, -1.61667705e+00, -1.40325932e+00,\n",
       "          -1.11051183e+00, -1.01701344e+00, -4.45101839e-01,\n",
       "          -5.28344129e-01,  4.66761720e-01, -1.02375955e+00,\n",
       "          -1.13750998e+00, -3.36020647e-01, -3.20530845e-01,\n",
       "          -1.00749555e-01,  1.96052633e+00, -1.33374650e+00,\n",
       "          -1.63519970e+00, -3.80457620e-01, -4.43308409e-01,\n",
       "          -9.65604394e-01,  3.10961329e+00, -9.69677996e-01,\n",
       "           9.78794550e-01, -4.89210876e-01, -1.90129016e+00,\n",
       "          -2.76973147e-01, -3.39559385e-01,  2.22970219e-02,\n",
       "          -7.02239580e-01, -1.39058698e-01],\n",
       "         [ 1.03084898e+00, -8.06323680e-01, -4.92772206e-01,\n",
       "          -2.26531205e-02, -1.85958360e+00,  2.27545979e-01,\n",
       "           9.21389923e-01,  1.88436559e-01, -1.76774173e+00,\n",
       "          -2.51639243e+00,  3.59976755e-01, -1.95535341e+00,\n",
       "          -1.48625998e+00, -2.19132637e+00,  5.62139144e-01,\n",
       "          -8.09921463e-02, -1.28436855e+00,  3.70120069e-01,\n",
       "          -2.20989558e+00, -1.21548503e+00,  7.54243086e-01,\n",
       "           6.25526873e-01,  1.06166305e+00,  1.78533473e+00,\n",
       "           1.19480105e+00,  3.85990539e-01,  1.20189336e-01,\n",
       "          -1.78720069e+00,  2.25291170e+00,  2.52396670e-01,\n",
       "           7.80001980e-01, -6.35065263e-01],\n",
       "         [ 2.19944946e+00, -1.42118217e+00, -4.95983122e-01,\n",
       "          -1.25890229e+00,  9.14423617e-01,  1.12332907e+00,\n",
       "           3.99557163e-02,  1.28148497e+00, -2.81752813e-01,\n",
       "           5.25086402e-01, -8.32839106e-01, -1.09050063e+00,\n",
       "          -2.02544918e+00, -4.39994455e-01,  8.29657548e-01,\n",
       "           6.20491930e-01,  1.35496216e+00,  2.50865119e+00,\n",
       "           4.96960167e-01,  1.87136098e+00,  1.86768162e+00,\n",
       "           2.70351099e-01,  1.74827272e-02,  5.11947960e-01,\n",
       "          -1.80125917e+00, -1.47296543e+00,  8.37047426e-01,\n",
       "          -4.35619069e-01, -8.44621153e-01, -1.23682018e+00,\n",
       "           1.66654002e+00,  5.43873502e-01],\n",
       "         [-1.56565279e-01, -2.19060983e-01, -2.20034179e-01,\n",
       "           1.44567522e-02, -3.02398931e+00,  9.71126329e-01,\n",
       "           6.23204711e-01, -3.07461841e-01, -9.97424925e-01,\n",
       "          -1.45808041e+00, -6.92497467e-01, -3.27549312e-01,\n",
       "          -1.41380656e+00, -2.25901146e-01,  2.78189802e-01,\n",
       "           4.49277311e-01, -1.24195592e+00, -3.01801355e-01,\n",
       "          -6.65698189e-01, -1.70676074e+00,  2.76844706e-01,\n",
       "          -9.22437184e-02,  1.20857751e-01, -2.04923806e+00,\n",
       "          -3.76165822e-02, -4.57103252e-01,  1.74187217e+00,\n",
       "          -1.52913287e-01, -1.36695182e-01,  6.14484963e-01,\n",
       "          -9.63042321e-01, -3.87959974e-01],\n",
       "         [-5.59144914e-01,  1.51642380e+00, -9.75844386e-02,\n",
       "           4.25622650e-01,  2.81722164e-01, -1.25079080e+00,\n",
       "          -6.65191763e-01, -9.86440140e-02, -1.48875721e+00,\n",
       "           2.51308255e-02,  6.88992955e-01,  1.26624609e+00,\n",
       "          -6.95945571e-01, -5.50525307e-04, -5.54321923e-01,\n",
       "           1.09296959e+00, -8.90987639e-01, -1.27407604e+00,\n",
       "           2.08061105e+00, -3.57385282e-01, -2.51320525e+00,\n",
       "           5.76648815e-01, -2.55852752e-01,  1.85851449e+00,\n",
       "          -2.57645270e+00, -1.44301841e+00, -1.43556799e+00,\n",
       "          -6.66095507e-01,  8.04401453e-01, -6.44752534e-01,\n",
       "          -7.70344293e-01,  1.50282080e-01],\n",
       "         [-9.76985053e-01,  1.08939274e+00, -1.58490548e+00,\n",
       "          -1.61769651e+00,  2.43226439e+00, -1.40440328e+00,\n",
       "          -3.61014856e-01, -1.00513624e+00, -8.19979106e-01,\n",
       "          -2.26567448e+00, -4.80181466e-01,  1.08086635e+00,\n",
       "          -9.61425919e-01, -7.96487891e-01, -7.35562604e-01,\n",
       "          -3.17529987e-01,  7.90534769e-01, -4.11696816e-01,\n",
       "          -4.23480075e-01, -1.11685304e+00,  2.82590314e+00,\n",
       "          -5.31172891e-01, -5.84546400e-01, -1.92599138e+00,\n",
       "          -2.82855109e+00,  9.19851268e-01,  8.17354634e-01,\n",
       "           4.33903892e-03,  2.03231162e+00,  3.59322822e-01,\n",
       "          -2.74870315e-01, -1.29965209e+00],\n",
       "         [-1.73429829e-01, -2.53624961e+00, -2.21253351e+00,\n",
       "           5.16948364e-01,  6.10548736e-01, -6.72590649e-01,\n",
       "           1.08868612e+00, -3.14829435e-01,  4.49234127e-01,\n",
       "           1.24465477e+00, -7.70254971e-01,  8.48276951e-01,\n",
       "          -4.94457442e-01, -2.53145598e-01,  8.35132400e-01,\n",
       "           1.34583844e+00, -3.62983440e-01, -1.83649673e+00,\n",
       "           1.53123605e+00, -1.43684724e+00, -4.33199777e+00,\n",
       "          -2.75129730e-01, -7.02799623e-01, -1.48434611e+00,\n",
       "          -1.23608929e+00,  1.09577174e+00,  1.28241921e-01,\n",
       "          -5.53881717e-01, -6.16234880e-01,  1.27526169e+00,\n",
       "          -8.82007621e-01, -2.62775550e-01]])],\n",
       " [array([[-1.48693493],\n",
       "         [ 0.24129808],\n",
       "         [ 0.39016331],\n",
       "         [-0.12877672],\n",
       "         [ 0.97308383],\n",
       "         [ 0.84028049],\n",
       "         [-0.04200511],\n",
       "         [-0.51133985],\n",
       "         [ 1.44335709],\n",
       "         [ 1.02760225],\n",
       "         [ 0.22354093],\n",
       "         [ 0.47648615],\n",
       "         [-1.23551987],\n",
       "         [-2.09039264],\n",
       "         [-2.42578156],\n",
       "         [ 0.14519844],\n",
       "         [-1.09690923],\n",
       "         [ 0.65596414],\n",
       "         [-0.67321376],\n",
       "         [ 0.10372258],\n",
       "         [ 0.97712043],\n",
       "         [ 0.76665095],\n",
       "         [-0.48739794],\n",
       "         [-0.60318256],\n",
       "         [-1.13992996],\n",
       "         [-0.40483887],\n",
       "         [ 1.15330109],\n",
       "         [ 1.67355243],\n",
       "         [-0.21737626],\n",
       "         [-1.83822143],\n",
       "         [-0.2705062 ],\n",
       "         [-1.18768501]]),\n",
       "  array([[-0.4467327 ],\n",
       "         [ 0.36313129],\n",
       "         [ 0.23165147],\n",
       "         [-1.70892719],\n",
       "         [-0.22959769],\n",
       "         [ 1.69753245],\n",
       "         [ 0.53815203],\n",
       "         [-1.09983121],\n",
       "         [-2.73697265],\n",
       "         [-0.28169239]])])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "weights = [np.random.randn(32, 784), np.random.randn(10, 32)]\n",
    "bias = [np.random.randn(32,1), np.random.randn(10,1)]\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "gradient_descent(X_train, y_train, weights, bias, activation_function=['sigmoid', 'sigmoid'], epochs = 1, learning_rate = 0.01, optimization_method='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
